{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import io\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from shapely import wkt\n",
    "from pandas.io.json import json_normalize\n",
    "import arcpy\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from sys import argv\n",
    "from os.path import exists\n",
    "import simplejson as json \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of files based on directory and extension inputs \n",
    "def lstFiles(rootPath, ext):\n",
    "    emptyList = []\n",
    "    root = rootPath\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for names in files: \n",
    "            if names.endswith(ext) and not names.startswith(\"._\"):\n",
    "                emptyList.append(path + '\\\\' + names)\n",
    "    return(emptyList)\n",
    "\n",
    "# Create new folder in root path \n",
    "def createFolder(rootPath, folderName): \n",
    "    folderPath = os.path.join(rootPath, folderName) \n",
    "    if not os.path.exists(folderPath):\n",
    "        os.makedirs(folderPath)\n",
    "    return folderPath + \"\\\\\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = r'F:\\BuildingChallenge'\n",
    "os.chdir(rootPath)\n",
    "\n",
    "trainData = 'train_images_labels_targets.tar'\n",
    "tier3Data = 'tier3.tar'\n",
    "testData = 'test_images_labels_targets.tar'\n",
    "holdData = 'hold_images_labels_targets.tar'\n",
    "\n",
    "\n",
    "\n",
    "tf = tarfile.open(os.path.join(rootPath, 'TarFiles', holdData))\n",
    "tf.extractall(rootPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = r'F:\\BuildingChallenge'\n",
    "\n",
    "def getDataInfo(rootPath, folderName):\n",
    "    json_files = lstFiles(os.path.join(rootPath, folderName), '.json')\n",
    "\n",
    "    locationName = []\n",
    "    disasterType = []  \n",
    "    ID = [] \n",
    "    pre_post = [] \n",
    "    date = [] \n",
    "    img_name = [] \n",
    "\n",
    "    for jsn in json_files: \n",
    "        nm = jsn.split(\"\\\\\")\n",
    "        fileName = nm[-1]\n",
    "        nmm = fileName.split(\"_\")\n",
    "        ID.append(str(nmm[1]))\n",
    "        pre_post.append(nmm[2])\n",
    "        img_name.append(fileName[:-5])\n",
    "        data = json.load(open(jsn))\n",
    "        disasterType.append(data['metadata']['disaster_type'])\n",
    "        date.append(data['metadata']['capture_date'])\n",
    "        locationName.append(data['metadata']['disaster'])\n",
    "\n",
    "    dataInfo = pd.DataFrame({ 'location_name': locationName, 'ID':ID, 'disaster_type': disasterType, \n",
    "                             'img_date': date, 'pre_post_disaster': pre_post, 'img_name':img_name})\n",
    "    return dataInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_firesDF = getDataInfo(rootPath, 'test_all')\n",
    "# test_firesDF.to_csv(os.path.join(rootPath, 'test_all' + '.csv'), index=False)\n",
    "# fire_test = test_firesDF[test_firesDF['disaster_type'] == 'fire']\n",
    "# fire_test.to_csv(os.path.join(rootPath, 'test_all' + '_fires.csv'), index=False)\n",
    "\n",
    "hold_firesDF = getDataInfo(rootPath, 'hold_all')\n",
    "# hold_firesDF.to_csv(os.path.join(rootPath, 'hold_all' + '.csv'), index=False)\n",
    "# fire_hold = hold_firesDF[hold_firesDF['disaster_type'] == 'fire']\n",
    "# fire_hold.to_csv(os.path.join(rootPath, 'hold_all' + '_fires.csv'), index=False)\n",
    "\n",
    "train_firesDF = getDataInfo(rootPath, 'train_all')\n",
    "# train_firesDF.to_csv(os.path.join(rootPath, 'train_all' + '.csv'), index=False)\n",
    "# fire_train = train_firesDF[train_firesDF['disaster_type'] == 'fire']\n",
    "# fire_train.to_csv(os.path.join(rootPath, 'train_all' + '_fires.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_name</th>\n",
       "      <th>ID</th>\n",
       "      <th>disaster_type</th>\n",
       "      <th>img_date</th>\n",
       "      <th>pre_post_disaster</th>\n",
       "      <th>img_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>guatemala-volcano</td>\n",
       "      <td>00000000</td>\n",
       "      <td>volcano</td>\n",
       "      <td>2018-06-22T16:55:40.000Z</td>\n",
       "      <td>post</td>\n",
       "      <td>guatemala-volcano_00000000_post_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>guatemala-volcano</td>\n",
       "      <td>00000000</td>\n",
       "      <td>volcano</td>\n",
       "      <td>2018-02-05T17:10:18.000Z</td>\n",
       "      <td>pre</td>\n",
       "      <td>guatemala-volcano_00000000_pre_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>guatemala-volcano</td>\n",
       "      <td>00000001</td>\n",
       "      <td>volcano</td>\n",
       "      <td>2018-06-22T16:55:40.000Z</td>\n",
       "      <td>post</td>\n",
       "      <td>guatemala-volcano_00000001_post_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>guatemala-volcano</td>\n",
       "      <td>00000001</td>\n",
       "      <td>volcano</td>\n",
       "      <td>2018-02-05T17:10:18.000Z</td>\n",
       "      <td>pre</td>\n",
       "      <td>guatemala-volcano_00000001_pre_disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>guatemala-volcano</td>\n",
       "      <td>00000002</td>\n",
       "      <td>volcano</td>\n",
       "      <td>2018-06-22T16:55:40.000Z</td>\n",
       "      <td>post</td>\n",
       "      <td>guatemala-volcano_00000002_post_disaster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location_name        ID disaster_type                  img_date  \\\n",
       "0  guatemala-volcano  00000000       volcano  2018-06-22T16:55:40.000Z   \n",
       "1  guatemala-volcano  00000000       volcano  2018-02-05T17:10:18.000Z   \n",
       "2  guatemala-volcano  00000001       volcano  2018-06-22T16:55:40.000Z   \n",
       "3  guatemala-volcano  00000001       volcano  2018-02-05T17:10:18.000Z   \n",
       "4  guatemala-volcano  00000002       volcano  2018-06-22T16:55:40.000Z   \n",
       "\n",
       "  pre_post_disaster                                  img_name  \n",
       "0              post  guatemala-volcano_00000000_post_disaster  \n",
       "1               pre   guatemala-volcano_00000000_pre_disaster  \n",
       "2              post  guatemala-volcano_00000001_post_disaster  \n",
       "3               pre   guatemala-volcano_00000001_pre_disaster  \n",
       "4              post  guatemala-volcano_00000002_post_disaster  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_firesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "rootPath = 'F:\\BuildingChallenge'\n",
    "\n",
    "def moveFiles(rootPath, inputFolder, folderDict, outputFolder, dataDF):\n",
    "    filterDF = dataDF[dataDF['disaster_type'] == 'fire']\n",
    "    for index, row in filterDF.iterrows():\n",
    "        for dic in folderDict: \n",
    "            flPath = os.path.join(rootPath, inputFolder, dic[0])\n",
    "            src = os.path.join(flPath, row.img_name + dic[1])\n",
    "            mainFolder = createFolder(os.path.join(rootPath, 'Data'), outputFolder)\n",
    "            eventFolder = createFolder(mainFolder, row.location_name)\n",
    "            IDFolder = createFolder(eventFolder, row.ID)\n",
    "            dst = os.path.join(IDFolder, row.img_name + dic[1])\n",
    "            copyfile(src, dst)\n",
    "\n",
    "folderExt = [['images', '.png'], ['labels', '.json'], ['targets', '_target.png']]\n",
    "\n",
    "moveFiles(rootPath, 'test_all', folderExt, 'test', test_firesDF)     \n",
    "moveFiles(rootPath, 'hold_all', folderExt,'hold', hold_firesDF)     \n",
    "moveFiles(rootPath, 'train_all', {'images' : 'png', 'labels' : '.json', 'targets': '_target.png'}, 'train', train_firesDF)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "\n",
    "rootPath = 'F:\\BuildingChallenge\\Data'\n",
    "\n",
    "def createGeoFiles(fullDF, inputFolder, outputFolder):\n",
    "    filterDF = fullDF[fullDF['disaster_type'] == 'fire']\n",
    "    for index, row in filterDF.iterrows():\n",
    "        #print(row.img_name)\n",
    "        try:\n",
    "            pth = os.path.join(rootPath, inputFolder, row.location_name, row.ID)\n",
    "            jsonFile = os.path.join(pth, row.img_name + '.json')\n",
    "            data = json.load(open(jsonFile)) # read as json file \n",
    "            df = json_normalize(data['features']['lng_lat']) # convert to df\n",
    "            df['wkt'] = df['wkt'].apply(wkt.loads)\n",
    "            gdf = gpd.GeoDataFrame(df, geometry='wkt') # read as geodf\n",
    "            gdf['date'] = row.img_date\n",
    "            gdf['pre_post_disaster'] = row.pre_post_disaster\n",
    "            gdf['disaster_type'] = row.disaster_type\n",
    "            gdf['location_name'] = row.location_name\n",
    "            gdf['ID'] = row.ID\n",
    "            if row.pre_post_disaster == 'pre': \n",
    "                gdf['damage'] = 'no-damage'\n",
    "            else: \n",
    "                gdf['damage'] = df['properties.subtype']\n",
    "\n",
    "            mainFolder = createFolder(rootPath, outputFolder)\n",
    "            eventFolder = createFolder(mainFolder, row.location_name)\n",
    "            IDFolder = createFolder(eventFolder, row.ID)\n",
    "            gdf.crs = {'init' :'epsg:4326'}\n",
    "            gdf.to_file(os.path.join(IDFolder, row.img_name + '.geojson'), driver='GeoJSON')\n",
    "            shpPath = createFolder(IDFolder, row.img_name)\n",
    "            gdf.to_file(os.path.join(shpPath, row.img_name + '.shp'))\n",
    "            gdf.plot(column='damage', cmap='PiYG')\n",
    "            plt.savefig(os.path.join(IDFolder, row.pre_post_disaster + \"_\" + row.location_name + '.png'))\n",
    "            plt.close()\n",
    "        except: \n",
    "            continue        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "createGeoFiles(train_firesDF, 'train', 'train_geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "createGeoFiles(test_firesDF, 'test', 'test_geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "createGeoFiles(hold_firesDF, 'hold', 'hold_geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F:\\\\BuildingChallenge\\\\Data\\\\test_geo\\\\santa-rosa-wildfire\\\\00000000\\\\santa-rosa-wildfire_00000000_post_disaster\\\\santa-rosa-wildfire_00000000_post_disaster.shp',\n",
       " 'F:\\\\BuildingChallenge\\\\Data\\\\test_geo\\\\santa-rosa-wildfire\\\\00000000\\\\santa-rosa-wildfire_00000000_pre_disaster\\\\santa-rosa-wildfire_00000000_pre_disaster.shp',\n",
       " 'F:\\\\BuildingChallenge\\\\Data\\\\test_geo\\\\santa-rosa-wildfire\\\\00000001\\\\santa-rosa-wildfire_00000001_post_disaster\\\\santa-rosa-wildfire_00000001_post_disaster.shp',\n",
       " 'F:\\\\BuildingChallenge\\\\Data\\\\test_geo\\\\santa-rosa-wildfire\\\\00000001\\\\santa-rosa-wildfire_00000001_pre_disaster\\\\santa-rosa-wildfire_00000001_pre_disaster.shp',\n",
       " 'F:\\\\BuildingChallenge\\\\Data\\\\test_geo\\\\santa-rosa-wildfire\\\\00000012\\\\santa-rosa-wildfire_00000012_post_disaster\\\\santa-rosa-wildfire_00000012_post_disaster.shp']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "# get all shapefiles in train folder \n",
    "# merge into one \n",
    "rootPath = 'F:\\BuildingChallenge\\Data'\n",
    "shp_files = lstFiles(os.path.join(rootPath, 'test_geo'), '.shp')\n",
    "shp_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'F:\\\\BuildingChallenge\\\\Data\\\\test_building.shp'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.Merge_management(shp_files, os.path.join(rootPath, 'test_building.shp')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
